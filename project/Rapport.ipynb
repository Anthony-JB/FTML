{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a57aea1",
   "metadata": {},
   "source": [
    "Anthony BERNARD, Junyi Li"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef5d737",
   "metadata": {},
   "source": [
    "<h1><center>FTML Project Report</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e53935ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72f37e2",
   "metadata": {},
   "source": [
    "## 1 bayes estimator and bayes risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc6d8b",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa599521",
   "metadata": {},
   "source": [
    "On choisit les paramètres suivants :\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{X} & =\\{1, 2, 3\\} \\\\\n",
    "\\mathcal{Y} & =\\{0, 1\\}\n",
    "\\end{aligned}\n",
    "$$\n",
    "$X$ suit une loi uniforme sur $\\mathcal{X}$\n",
    "$$\n",
    "Y=\\left\\{\\begin{array}{l}\n",
    "Q(1 / 4) \\text { if } X=1 \\\\\n",
    "Q(2 / 5) \\text { if } X=2 \\\\\n",
    "Q(3 / 4) \\text { if } X=3\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "Avec $Q(p)$ un loi de paramètre $p$, telle que :\n",
    "$$\n",
    "P(X=x)=\\left\\{\\begin{array}{l}\n",
    "p \\text { if } x=0 \\\\\n",
    "1-p \\text { if } x=1 \\\\\n",
    "0 \\text { else }\n",
    "\\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5ac029",
   "metadata": {},
   "source": [
    "On choisit la \"0-1\" loss $l(y, z)=1_{y \\neq z}$.  \n",
    "L'estimateur de Bayes est défini par :\n",
    "$$\n",
    "f^*(x)=\\arg \\min E[l(y, z) \\mid X=x]\n",
    "$$\n",
    "Ainsi :\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f^*(x) & =\\arg \\min E[l(y, z) \\mid X=x] \\\\\n",
    "& =\\arg \\min P(Y \\neq z \\mid X=x) \\\\\n",
    "& =1-\\arg \\min P(Y=z \\mid X=x) \\\\\n",
    "& =\\arg \\max P(Y=z \\mid X=x)\n",
    "\\end{aligned}\n",
    "$$\n",
    "On obtient:\n",
    "\\begin{aligned}\n",
    "-f^*(1) & =1 \\\\\n",
    "-f^*(2) & =1 \\\\\n",
    "-f^*(3) & =0\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0657d014",
   "metadata": {},
   "source": [
    "On va calculer le risque de Bayes :\n",
    "$$\n",
    "\\begin{aligned}\n",
    "R^*(x) & =E\\left[l\\left(Y, f^*(X)\\right)\\right] \\\\\n",
    "& =E_X\\left[E_Y\\left(l\\left(Y \\neq f^*(X) \\mid X\\right)\\right)\\right] \\\\\n",
    "& =E_X\\left[P\\left(Y \\neq f^*(X) \\mid X\\right)\\right]\n",
    "\\end{aligned}\n",
    "$$\n",
    "Sachant que :\n",
    "$$\n",
    "P\\left(Y \\neq f^*(X) \\mid X=x\\right)=P\\left(Y \\neq f^*(x)\\right)\n",
    "$$\n",
    "On note $\\eta(x)=P(Y=0 \\mid X=x)$. Then :\n",
    "- Si $\\eta(x)>\\frac{1}{2}$, alors $f^*(x)=0$, et $P\\left(Y \\neq f^*(x)\\right)=P(Y=1)=1-\\eta(x)$\n",
    "- Si $\\eta(x)<\\frac{1}{2}$, alors $f^*(x)=1$, et $P\\left(Y \\neq f^*(x)\\right)=P(Y=0)=\\eta(x)$  \n",
    "ON obtient, $P\\left(Y \\neq f^*(x)\\right)=\\min (\\eta(x), 1-\\eta(x))$.  \n",
    "Donc\n",
    "$$\n",
    "R^*=E_X[\\min (\\eta(X), 1-\\eta(X)]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8877c5",
   "metadata": {},
   "source": [
    "On applique :\n",
    "$$\n",
    "\\begin{aligned}\n",
    "R^* & =\\frac{1}{3} *\\frac{1}{4}+\\frac{1}{3} *\\frac{2}{5}+\\frac{1}{3} *\\frac{1}{4} \\\\\n",
    "R^* & =\\frac{3}{10}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf6035",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78d8ebf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d: 1\n",
      "plot\n",
      "d: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SIGMA = 8\n",
    "BAYES_RISK = SIGMA**2\n",
    "\n",
    "def generate_output_data(\n",
    "    X: np.ndarray, theta_star, sigma: float, rng, n_tests: int\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    generate input and output data (supervised learning)\n",
    "    according to the linear model, fixed design setup\n",
    "    - X is fixed\n",
    "    - y is random, according to\n",
    "\n",
    "    Y = Xtheta_star + epsilon\n",
    "\n",
    "    We use numpy matrix manipulations in order\n",
    "    to directly generate a number of output vectors.\n",
    "\n",
    "    where epsilon is a centered gaussian noise vector with variance\n",
    "    sigma*In\n",
    "\n",
    "    Parameters:\n",
    "        X: (n, d) design matrix\n",
    "        theta_star\n",
    "        sigma (float): variance of the noise\n",
    "\n",
    "    Returns:\n",
    "        Y (float matrix): output vector (n, 1)\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    noise = rng.normal(0, sigma, size=(n, n_tests))\n",
    "    y = theta_star(X) + noise\n",
    "    return y\n",
    "\n",
    "def ridge_regression_estimator(\n",
    "    X: np.ndarray, y: np.ndarray, lambda_: float\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the Ridge regression estimator\n",
    "\n",
    "    We use numpy broadcasting to accelerate computations\n",
    "    and obtain several Ridge estimators.\n",
    "\n",
    "    Parameters:\n",
    "        X: (n, d) matrix\n",
    "        y: (n, n_tests) matrix\n",
    "        lambda: regularization parameter\n",
    "\n",
    "    Returns:\n",
    "        theta_hat: (d, n_tests) matrix\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    covariance_matrix = X.T @ X\n",
    "    Sigma_matrix = covariance_matrix / n\n",
    "    theta_hat = 1 / n * np.linalg.inv(Sigma_matrix + lambda_ * np.identity(d)) @ X.T @ y\n",
    "    return theta_hat\n",
    "\n",
    "def q_law(x, p):\n",
    "    return p if x == 0 else (1 - p if x == 1 else 0)\n",
    "\n",
    "def bayes_predictor(x):\n",
    "    if x == 1:\n",
    "        return 0 if q_law(0, 1/4) > q_law(1, 1/4) else 1\n",
    "    if x == 2:\n",
    "        return 0 if q_law(0, 2/5) > q_law(1, 2/5) else 1\n",
    "    if x == 3:\n",
    "        return 0 if q_law(0, 3/4) > q_law(1, 3/4) else 1\n",
    "    \n",
    "def ridge_risk(n, d, lambda_, n_tests) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Statistical evaluation of the excess risk of the Ridge regression\n",
    "    estimator\n",
    "\n",
    "    n_test times, do:\n",
    "        - Draw output vector Y, according to the linear model, fixed\n",
    "        design setup.\n",
    "        - compute the corresponding Ridge estimator\n",
    "        - generate a test test in order to have an estimation of the excess risk of\n",
    "        this estimator (generalization error)\n",
    "\n",
    "    Parameters:\n",
    "        n (int): number of samples in the dataset\n",
    "        d (int): dimension of each sample (number of features)\n",
    "        n_tests (int): number of simulations run\n",
    "\n",
    "    Returns:\n",
    "        risk_estimation (float): estimation of the excess risk of the ridge\n",
    "        estimator in this setup.\n",
    "    \"\"\"\n",
    "    # instantiate a PRNG\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    # design matrix\n",
    "    X = np.array([[rng.choice([1, 2, 3]) for _ in range(d)] for _ in range(n)])\n",
    "\n",
    "    # Bayes predictor\n",
    "    theta_star = np.vectorize(bayes_predictor)\n",
    "\n",
    "    # run several simulations to have an estimation of the excess risk\n",
    "    y = generate_output_data(X, theta_star, SIGMA, rng, n_tests)\n",
    "\n",
    "    # compute the Ridge regression estimator\n",
    "    theta_hat = ridge_regression_estimator(X, y, lambda_)\n",
    "\n",
    "    # generate test data\n",
    "    y_test = generate_output_data(X, theta_star, SIGMA, rng, n_tests)\n",
    "\n",
    "    # compute predictions of each OLS estimator\n",
    "    y_pred = X @ theta_hat\n",
    "\n",
    "    mean_test_error = np.linalg.norm(y_pred - y_test) ** 2 / (n * n_tests)\n",
    "\n",
    "    return mean_test_error\n",
    "\n",
    "def plot_test_errors_ridge(\n",
    "    risks: dict[tuple, float], d_list: list[int], n: int, lambda_list: list[int]\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Display all the computed risks on a plot\n",
    "    \"\"\"\n",
    "    colors = [\"blue\", \"green\", \"darkred\", \"mediumvioletred\", \"darkmagenta\"]\n",
    "    index = 0\n",
    "    print(\"plot\")\n",
    "\n",
    "    # plot the risks for each n and d\n",
    "    for index, d in enumerate(d_list):\n",
    "        print(f\"d: {d}\")\n",
    "        color = colors[index]\n",
    "        risk_estimates = [risks[d, lambda_] for lambda_ in lambda_list]\n",
    "        ols_risk = BAYES_RISK + SIGMA**2 * d / n\n",
    "        alpha = 0.6\n",
    "        # extended label for the first ont\n",
    "        label_est = f\"Ridge test error, d={d}\"\n",
    "        label_ols = f\"OLS risk, d={d}\"\n",
    "        plt.plot(\n",
    "            lambda_list,\n",
    "            risk_estimates,\n",
    "            label=label_est,\n",
    "            color=color,\n",
    "            markersize=3,\n",
    "            alpha=alpha,\n",
    "        )\n",
    "        plt.plot(\n",
    "            lambda_list,\n",
    "            [ols_risk] * len(lambda_list),\n",
    "            label=label_ols,\n",
    "            color=\"darkmagenta\",\n",
    "            alpha=alpha,\n",
    "        )\n",
    "\n",
    "    plt.plot(\n",
    "        lambda_list,\n",
    "        [BAYES_RISK] * len(lambda_list),\n",
    "        label=\"Bayes risk: \" + r\"$\\sigma^2$\",\n",
    "        color=\"aqua\",\n",
    "    )\n",
    "\n",
    "    # finish plot\n",
    "    plt.xlabel(r\"$\\lambda$\")\n",
    "    plt.ylabel(\"test error\")\n",
    "    plt.title(\n",
    "        \"Ridge regression: risks as a function of \" + r\"$\\lambda$\"\n",
    "    )\n",
    "    plt.legend(loc=\"best\", fontsize=6)\n",
    "\n",
    "# dimensions of the problem\n",
    "n_list = [30]\n",
    "n = 30\n",
    "# d_list = list(range(0, 1000, 200))\n",
    "# d_list.remove(0)\n",
    "d_list = [1]\n",
    "bayes_risk = 3/10\n",
    "\n",
    "exponents = [k for k in range(-6, 6)]\n",
    "lambda_list = [10 ** (u) for u in exponents]\n",
    "\n",
    "# number of tests to estimate the excess risk\n",
    "n_tests = int(1e4)\n",
    "\n",
    "# Assess the influence of different values of n and d\n",
    "test_errors = dict()\n",
    "for d in d_list:\n",
    "    print(f\"d: {d}\")\n",
    "    for lambda_ in lambda_list:\n",
    "        # print(f\"lambda: {lambda_}\")\n",
    "        for n in n_list:\n",
    "            test_errors[(d, lambda_)] = ridge_risk(n, d, lambda_, n_tests)\n",
    "plot_test_errors_ridge(test_errors, d_list, 30, lambda_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b5b48d",
   "metadata": {},
   "source": [
    "The generalization error is smaller for $f^*$ than for $\\tilde{f}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac3d574",
   "metadata": {},
   "source": [
    "## 2 bayes risk with absolute loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2f84be",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5740fe",
   "metadata": {},
   "source": [
    "$\\mathrm{P}(\\mathrm{Y} \\mid \\mathrm{X}=\\mathrm{x})$ where $\\mathrm{Y} \\mid \\mathrm{X}=\\mathrm{x}$ correspond à une distribution continue $\\operatorname{Exp}(\\lambda)$.  \n",
    "L'estimateur de Bayes pour la $l_2$ squared loss\n",
    "$$\n",
    "f_2^*(x)=E[Y \\mid X=x]=E\\left[\\lambda e^{-\\lambda}\\right]=\\frac{1}{\\lambda}\n",
    "$$\n",
    "L'estimateur de Bayes pour la $l_1$ absolute loss est la médiane de $\\mathrm{Y} \\mid \\mathrm{X}=\\mathrm{x}$\n",
    "$$\n",
    "f_1^*(x)=\\frac{\\ln (2)}{\\lambda}\n",
    "$$\n",
    "ON a bien 2 estimateurs différents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1f070f",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1503c71",
   "metadata": {},
   "source": [
    "On note $p=\\mathrm{P}(\\mathrm{Y} \\mid \\mathrm{X}=\\mathrm{x})$\n",
    "$$\n",
    "\\begin{gathered}\n",
    "g(z)=\\int_{\\mathbb{R}}|y-z| p(y) d y \\\\\n",
    "=\\int_z^{+\\infty} y p(y) d y-z \\int_z^{+\\infty} p(y) d y+z \\int_{-\\infty}^z p(y) d y-\\int_{-\\infty}^z y p(y) d y \\\\\n",
    "\\frac{d}{d z} g(z)=-z p(z)-\\left(\\int_z^{+\\infty} p(y) d y-z p(z)\\right)+\\left(\\int_{-\\infty}^z p(y) d y+z p(z)\\right)-z p(z) \\\\\n",
    "=\\int_{-\\infty}^z p(y) d y-\\int_z^{+\\infty} p(y) d y\n",
    "\\end{gathered}\n",
    "$$\n",
    "On obtient, $\\frac{d}{d z} g(z)=0$ si :\n",
    "$$\n",
    "\\int_{-\\infty}^z p(y) d y=\\int_z^{+\\infty} p(y) d y\n",
    "$$\n",
    "On a ce résultat, si on trouve $\\frac{1}{2}$ des deux côtés, donc l'estmiateur de Bayes $f^*(x)$ est la médianne.  \n",
    "On va confirmé qu'il sagit d'un minimum de $\\mathrm{g}(\\mathrm{z})$, dérivée seconde:\n",
    "$$\n",
    "\\frac{d^2}{d z^2} g(z)=2 p(z)>0\n",
    "$$\n",
    "Elle est positive donc on a un minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551dcf3d",
   "metadata": {},
   "source": [
    "## 3 expected value of empirical risk for ols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eec1a86",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba59525d",
   "metadata": {},
   "source": [
    "On veut montrer que $\\mathbb{E}\\left(R_n(\\hat{\\theta})\\right)=\\mathbb{E}_\\epsilon\\left(\\frac{1}{n}\\left\\|\\left(I_n-X\\left(X^T X\\right)^{-1} X^T\\right) \\epsilon\\right\\|^2\\right)$  \n",
    "Or $R_n(\\hat{\\theta})=\\frac{1}{n}\\|Y-X \\hat{\\theta}\\|^2$ et $\\hat{\\theta}=\\left(X^T X\\right)^{-1} X^T Y$ et $Y=X \\theta^*+\\epsilon$  \n",
    "Donc:\n",
    "$$  \n",
    "\\begin{aligned}\n",
    "R_n(\\hat{\\theta}) & =\\frac{1}{n}\\left\\|X \\theta^*+\\epsilon-X\\left(X^T X\\right)^{-1} X^T\\left(X \\theta^*+\\epsilon\\right)\\right\\|^2 \\\\\n",
    "& =\\frac{1}{n}\\left\\|X \\theta^*+\\epsilon-X\\left(X^T X\\right)^{-1} X^T X \\theta^*+X\\left(X^T X\\right)^{-1} X^T \\epsilon\\right\\|^2 \\\\\n",
    "& =\\frac{1}{n}\\left\\|\\epsilon\\left(I_n-X\\left(X^T X\\right)^{-1} X^T\\right)\\right\\|^2\n",
    "\\end{aligned}\n",
    "$$\n",
    "Donc $\\mathbb{E}\\left(R_n(\\hat{\\theta})\\right)=\\mathbb{E}_\\epsilon\\left(\\frac{1}{n}\\left\\|\\left(I_n-X\\left(X^T X\\right)^{-1} X^T\\right) \\epsilon\\right\\|^2\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08783ff",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6e56de",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{gathered}\n",
    "A \\in \\mathbb{R}^{n, m} B \\in \\mathbb{R}^{n, m} \\\\\n",
    "\\operatorname{tr}\\left(A^T B\\right)=\\sum_{i, j \\in[1, n] \\times[1, m]} a_{i j} b_{i j}\n",
    "\\end{gathered}\n",
    "$$\n",
    "ON en conclut::\n",
    "$$\n",
    "\\begin{aligned}\n",
    "A & \\in \\mathbb{R}^{n, n} \\\\\n",
    "\\operatorname{tr}\\left(A^T A\\right) & =\\sum_{i, j} a_{i j} a_{i j}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ac1a2f",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912f3470",
   "metadata": {},
   "source": [
    "$\\begin{aligned}E\\left[\\frac{1}{n}\\|A \\varepsilon\\|^2\\right] & =E\\left[\\frac{1}{n} \\sum_{i=1}^n\\left(A_i \\varepsilon\\right)^2\\right] \\\\ \n",
    "& =E\\left[\\frac{1}{n} \\sum_{i=1}^n\\left(\\varepsilon^T A_i^T\\right)^2\\right] \\\\ \n",
    "& =E\\left[\\frac{1}{n} \\sum_{i=1}^n\\left(\\varepsilon^T A_i^T A_i \\varepsilon\\right)\\right] \\\\ \n",
    "& =E\\left[\\frac{1}{n} \\sum_{i=1}^n\\left(\\varepsilon^T \\varepsilon A_i^T A_i\\right)\\right] \\\\ \n",
    "& =E\\left[\\frac{1}{n} \\varepsilon^T \\varepsilon \\sum_{i=1}^n\\left(A_i^T A_i\\right)\\right] \\\\ \n",
    "& =E\\left[\\frac{1}{n} \\varepsilon^2 \\sum_{(i j) \\in[1, n]^2}\\left(A_{i j}^2\\right)\\right] \\\\ \n",
    "& =\\frac{\\sigma^2}{n} \\operatorname{Tr}\\left(A^T A\\right)\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508ad0ca",
   "metadata": {},
   "source": [
    "### Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c32b135",
   "metadata": {},
   "source": [
    "$\\begin{gathered}A^t A=I_n-2 I_n X\\left(X^t X\\right)^{-1} X^t+X\\left(X^t X\\right)^{-1} X^t X\\left(X^t X\\right)^{-1} X^t \\\\ A^t A=I_n-2 X\\left(X^t X\\right)^{-1} X^t+X\\left(X^t X\\right)^{-1} X^t \\\\ \n",
    "A^t A=I_n-X\\left(X^t X\\right)^{-1} X^t \\\\ \n",
    "A^t A=A\\end{gathered}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063ddd82",
   "metadata": {},
   "source": [
    "### Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26f9332",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{gathered}\n",
    "E\\left[R_n(\\hat{\\theta})\\right]=E_\\epsilon\\left[\\frac{1}{n}\\left\\|\\left(I_n-X\\left(X^T X\\right)^{-1} X^T\\right) \\epsilon\\right\\|_2^2\\right] \\\\\n",
    "=\\frac{\\sigma^2}{n} \\operatorname{tr}\\left(I_n-X\\left(X^T X\\right)^{-1} X^T\\right) \\\\\n",
    "=\\frac{\\sigma^2}{n}\\left(n-\\operatorname{tr}\\left(X\\left(X^T X\\right)^{-1} X^T\\right)\\right) \\\\\n",
    "=\\frac{\\sigma^2}{n}\\left(n-\\operatorname{tr}\\left(X^T X\\left(X^T X\\right)^{-1}\\right)\\right) \\\\\n",
    "=\\frac{\\sigma^2}{n}\\left(n-\\operatorname{tr}\\left(I_d\\right)\\right) \\\\\n",
    "=\\frac{\\sigma^2}{n}(n-d)\n",
    "\\end{gathered}\n",
    "$$\n",
    "Ainsi:\n",
    "$$\n",
    "E\\left[R_X(\\hat{\\theta})\\right]=E\\left[E\\left[R_n(\\hat{\\theta})\\right]\\right]=E\\left[\\frac{n-d}{n} \\sigma^2\\right]=\\frac{n-d}{n} \\sigma^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec495e40",
   "metadata": {},
   "source": [
    "### Q6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9729d645",
   "metadata": {},
   "source": [
    "On obtient:  \n",
    "$$\n",
    "\\frac{\\|y-\\widehat{\\theta}\\|}{n-d} \\sigma^2=\\frac{n-d}{n-d} \\sigma^2=\\sigma^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d5427d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma value is {} 0.0625\n",
      "Sigma estimator is {} 0.06099973573401494\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "d = 23\n",
    "sigma = 0.25\n",
    "n = 5000\n",
    "theta = rng.rand(d).reshape(d, 1)\n",
    "\n",
    "X = rng.rand(n, d)\n",
    "epsilon = rng.normal(0, sigma, size=(n, 1))\n",
    "y = X @ theta + epsilon\n",
    "theta_hat = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "sigma_estimator = np.linalg.norm(y - X @ theta_hat) ** 2 / (n - d)\n",
    "print(\"Sigma value is {}\",format(float(sigma**2)))\n",
    "print(\"Sigma estimator is {}\",format(float(sigma_estimator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c764facb",
   "metadata": {},
   "source": [
    "On a bien un résultat cohérent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
